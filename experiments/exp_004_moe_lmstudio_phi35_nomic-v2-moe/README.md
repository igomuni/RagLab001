# 実験004: MoE LM Studio + Phi-3.5 + Nomic v1.5

**日付**: 未実施
**ステータス**: 🚧 準備完了（実行待ち）

## 設定

- **LLM**: LM Studio Phi-3.5-mini-instruct（外部SSDに保存）
- **埋め込み**: nomic-embed-text v1.5 (768次元、MoEアーキテクチャ、Ollama経由)
- **チャンク**: 500文字、50オーバーラップ
- **データ**: 日本語桃太郎テキスト3件 (21チャンク)

## 目的

最高性能の組み合わせ（Phi-3.5 + MoE埋め込み）を検証し、全4実験の総合的な比較を完成させる。

## 主要な調査項目

1. **最適な組み合わせ**: 高性能LLM + 高品質埋め込みの効果
2. **相乗効果の検証**: 両方の改善が応答品質にどう影響するか
3. **計算コスト**: 最高品質構成のリソース要求
4. **実用性評価**: 本番環境での実用可能性

## 比較対象

- **exp_002**: 同じLLMだが nomic-v1 埋め込み（埋め込みの影響を分離）
- **exp_003**: 同じ埋め込みだが Ollama + phi3（LLMの影響を分離）
- **exp_001**: ベースライン構成（両方の改善効果を測定）

## ペア比較マトリクス

| 比較 | 変更した変数 | 目的 |
|------|------------|------|
| exp_004 vs exp_002 | 埋め込み (v1 → v1.5 MoE) | MoE埋め込みの効果測定 |
| exp_004 vs exp_003 | LLM (phi3 → phi-3.5) | LLMモデルの影響測定 |
| exp_004 vs exp_001 | 両方 | 総合的な改善効果 |

## ファイル

- **ノートブック**: [notebook.ipynb](notebook.ipynb)
- **設定**: [config.json](config.json)
- **ベクトル**: vectors/ (Git除外)
- **結果**: results/ (Git除外)

## 実行前の準備

1. LM Studioを起動し、Phi-3.5-mini-instructモデルをロード
2. LM StudioのLocal Serverを起動 (http://localhost:1234)
3. Ollamaが起動していることを確認（埋め込み生成用）
4. 必要なモデルをプル:
   ```bash
   ollama pull nomic-embed-text:latest  # v1.5を含む
   ```
5. ノートブックを開いて全セルを実行

## 予想される結果

### 仮説

1. **最高品質の応答**: Phi-3.5の高い指示追従性 + MoEの高品質検索
2. **最も詳細な応答**: exp_002よりも更に洗練された応答
3. **最高の計算コスト**: 両方とも高性能モデルのため、最もリソースを消費

### 評価基準

- RAG応答の正確性と詳細度（4実験中で最高を期待）
- 計算時間の総合評価（埋め込み + LLM推論）
- コストパフォーマンスの評価

## 実験後の分析

実験実施後、以下を記録:

1. **パフォーマンス指標**
   - RAG平均応答長
   - Non-RAG平均応答長
   - 総合的な計算時間

2. **定性的評価**
   - 応答の正確性 (1-5)
   - 応答の完全性 (1-5)
   - 文脈との整合性 (1-5)
   - 応答の洗練度 (1-5)

3. **4実験の総合比較**
   - LLMモデルの影響分析
   - 埋め込みモデルの影響分析
   - 最適な組み合わせの推奨
   - ユースケース別の推奨事項

## モデルの利点（予想）

- **最高品質**: 詳細で正確、指示追従性が高い
- **文脈理解**: 検索品質と生成品質の両方が最高レベル
- **本番環境向け**: 品質重視のプロダクションワークロードに最適

## トレードオフ

- **リソース消費**: 最も多くのメモリとCPU/GPUを使用
- **レイテンシ**: 応答時間が最も長い可能性
- **セットアップ複雑性**: LM StudioとOllama両方が必要

## 次のステップ

実験完了後:

1. 4実験すべての結果を統合
2. 総合比較レポートを作成:
   - LLMモデルの影響分析
   - 埋め込みモデルの影響分析
   - 組み合わせ効果の分析
3. ユースケース別の推奨事項をまとめる:
   - 開発/プロトタイピング
   - 本番環境/高精度要求
   - リソース制約のある環境
4. 次期実験の方向性を決定:
   - 他の言語でのテスト
   - チャンク戦略の最適化
   - より大きなLLMモデルの検証
