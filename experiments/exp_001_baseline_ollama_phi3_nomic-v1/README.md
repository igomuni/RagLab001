# 実験001: ベースライン Ollama + Phi3 + Nomic v1

**日付**: 2026-01-13
**ステータス**: ✅ 完了

## 設定

- **LLM**: Ollama phi3 (2.2GB)
- **埋め込み**: nomic-embed-text v1 (768次元)
- **チャンク**: 500文字、50オーバーラップ
- **データ**: 日本語桃太郎テキスト3件 (21チャンク)

## 目的

標準モデルでRAG有無のパフォーマンスを確立するベースライン実験。

## 主要な発見事項

- RAG平均応答長: 140.4文字
- Non-RAG平均応答長: 122.4文字
- RAG応答は正確でソース資料に基づいている
- Non-RAG応答は深刻なハルシネーションを示す（架空のキャラクター作成: "姉さん"、"明"）

## パフォーマンス指標

| 指標 | RAG | Non-RAG |
|------|-----|---------|
| 平均応答長 | 140.4文字 | 122.4文字 |
| 精度 | 高 ✅ | 低 ❌ |
| ハルシネーション | なし | 深刻 |

## 比較対象

- **exp_002**: 同じ設定だがLM Studio + Phi-3.5（より詳細な応答、指示追従性が向上）
- **exp_003**: 同じLLMだがnomic-v2-moe埋め込み（計画中 - MoE埋め込みの影響をテスト予定）

## ファイル

- **ノートブック**: [notebook.ipynb](notebook.ipynb)
- **結果**: [results/experiment_results_20260113_092450.json](results/experiment_results_20260113_092450.json)
- **比較レポート**: [docs/20260113_0930_MVP実験結果_OllamaとLMStudio比較.md](../../docs/20260113_0930_MVP実験結果_OllamaとLMStudio比較.md)

## 結論

1. **RAGは必須**: Non-RAGモードは深刻なハルシネーションのため使用不可
2. **Phi-3の特徴**:
   - 簡潔な応答（RAG使用時平均140文字）
   - 時折コンテキストを過剰解釈する傾向
   - 高速で軽量
3. **セットアップの簡潔性**: 単一ツール（Ollama）により最も簡単な構成

## 次のステップ

- nomic-embed-text-v2-moe（exp_003）でテストし、埋め込み品質を比較
- より大きなLLMモデル（qwen2.5:7b）との比較を検討
