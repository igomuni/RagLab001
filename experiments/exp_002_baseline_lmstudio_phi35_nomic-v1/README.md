# 実験002: ベースライン LM Studio + Phi-3.5 + Nomic v1

**日付**: 2026-01-12
**ステータス**: ✅ 完了

## 設定

- **LLM**: LM Studio Phi-3.5-mini-instruct（外部SSDに保存）
- **埋め込み**: nomic-embed-text v1 (768次元、Ollama経由)
- **チャンク**: 500文字、50オーバーラップ
- **データ**: 日本語桃太郎テキスト3件 (21チャンク)

## 目的

LM StudioとPhi-3.5モデルを使用したベースライン実験で、パフォーマンス特性を確立し、Ollama/Phi-3と比較する。

## 主要な発見事項

- RAG平均応答長: 200.4文字
- Non-RAG平均応答長: 276.8文字
- RAG応答は正確で詳細
- Non-RAG応答はハルシネーションを示す（架空のキャラクター作成: "弥三石"）
- Phi-3.5はPhi-3と比較して指示追従性が向上

## パフォーマンス指標

| 指標 | RAG | Non-RAG |
|------|-----|---------|
| 平均応答長 | 200.4文字 | 276.8文字 |
| 精度 | 高 ✅ | 低 ❌ |
| ハルシネーション | なし | 中程度 |
| 詳細度 | 良好 | 過剰 |

## 比較対象

- **exp_001**: 同じ埋め込みだがOllama + Phi-3（より簡潔、詳細度低）
- **exp_004**: 同じLLMだがnomic-v2-moe埋め込み（計画中 - MoE埋め込みの影響をテスト予定）

## ファイル

- **ノートブック**: [notebook.ipynb](notebook.ipynb)
- **結果**: [results/experiment_results_lmstudio_20260112_090749.json](results/experiment_results_lmstudio_20260112_090749.json)
- **比較レポート**: [docs/20260113_0930_MVP実験結果_OllamaとLMStudio比較.md](../../docs/20260113_0930_MVP実験結果_OllamaとLMStudio比較.md)

## 結論

1. **RAGは必須**: Non-RAGモードはハルシネーションを生成するが、Phi-3ほど深刻ではない
2. **Phi-3.5の特徴**:
   - より詳細な応答（RAG使用時平均200文字）
   - コンテキスト忠実性が向上
   - 指示追従性が優れている
   - Phi-3と比較してやや冗長
3. **セットアップの複雑さ**: LM StudioとOllama（埋め込み用）の両方が必要

## モデルの利点

- **本番環境向け**: 高精度と詳細度
- **コンテキスト処理**: Phi-3.5はコンテキストから事実を抽出する能力が向上
- **一貫性**: 異なる質問タイプに対してより信頼性の高い応答

## 次のステップ

- nomic-embed-text-v2-moe（exp_004）でテストし、埋め込み品質を比較
- 速度/品質のトレードオフのため、異なる量子化レベルでのテストを検討
